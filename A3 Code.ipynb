{"cells":[{"cell_type":"markdown","metadata":{"id":"0mgRrjQ-UiMc"},"source":["# Packages"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6631,"status":"ok","timestamp":1649083669272,"user":{"displayName":"Jonayed Islam","userId":"15230808736385328806"},"user_tz":240},"id":"AY-e5iZmCKRc"},"outputs":[],"source":["import numpy as np\n","import numpy.random as random\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sn\n","random.seed(1234)"]},{"cell_type":"markdown","metadata":{"id":"TyrinVrtUqus"},"source":["# Dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1649083669273,"user":{"displayName":"Jonayed Islam","userId":"15230808736385328806"},"user_tz":240},"id":"lRSpz1KisRCA"},"outputs":[],"source":["batchsize = 2000"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476,"referenced_widgets":["c2ba37d500c8426897d309e934bfb8fd","549d3570fdcf48b9bc1d5f5b89ecb281","c2b50f1160e94e7ba2d6c0da4351146f","f1dc550b0fbe44d6b6c5f88910955ba3","c1b5df538c114c2d90a6d6b8061edffd","27755f22e07b4533a6cd1f036bab6e88","7a9b7db00ab144289ab05edfdedc2b5b","5c3959b55adc4e44b93181c298177443","303b8e0a6c2f476f86de14e690cae0c3","ed392b6d74e34bc591090fa87a1d5fed","36dd408c2d8140f28bc49fb15ca0a8fe","b7321e15bab347559fdd8b810d351e39","e0b4fbea478c48da8f249af6579544d3","acbc23a8881a4e8b89fc6c3e1f4b2936","5b9186cf350a44b782bc2eb3592d7c06","6c0b3ebd07ba492f903e2fab86ae59cd","3cbaf45f137f4c2f9370319df73c15d9","80d6b8eae5d0446782041136711d312a","809858bc1b414b5281d5ce29f1d740ad","913959e0d8944bf6b1dff64ba5c057cd","de971789d0e44fbdbfc5ab270b2791d7","2483910c1a084ff9a8492aee34d10d31","af41a2dd0dfd464586207bfc12b7e75e","ec7f5cc71bd6432c83a2a25688da675a","042df4ffcf544738a0ddc4a667d7d765","4f9c8fb7519741db916a91748f77c35d","d00d10d3f50a42c39828a54932a28ff7","d8f1248cc43e4f85ba2d56c33e88e383","0e05874a2dec4ecd975841dcf88c8300","778c273fdf6840409db9b951aecc40b9","fd254902e50f48929754ab965d21c9e8","3d59c0e07fc34711ba281744e99d9902","5846f1f851ae4d0fa119904d23ecf84f","8570181d28904a4090ba83f6f9600cfa","44a36774046e41259bbfd9abbb9e18af","c30deffe234f4a71be74985a86271161","62da865db2d040b0a0253e2c954c33a5","abc2177e726a4907b71fd116f1bc5852","bd4c63eb6f754a98b0e5306c38ecd050","d4fa0b67a5bb4c8e9cb76af5f39b376a","88426f710ecd4bac93d73cd59fa6e5f5","b81c72c3b1354bd49d901b738aa24401","c5811583bcfb4315b3b561346adec711","38c9c0291c484a968785a7f4ef961630"]},"executionInfo":{"elapsed":15551,"status":"ok","timestamp":1649083684816,"user":{"displayName":"Jonayed Islam","userId":"15230808736385328806"},"user_tz":240},"id":"_1Y5VobLSqf_","outputId":"18ca1c2b-4688-481c-e84a-e3a37bb700e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/26421880 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2ba37d500c8426897d309e934bfb8fd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./FashionMNIST/raw/train-images-idx3-ubyte.gz to ./FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/29515 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7321e15bab347559fdd8b810d351e39"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/4422102 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af41a2dd0dfd464586207bfc12b7e75e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/5148 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8570181d28904a4090ba83f6f9600cfa"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n","\n","Feature batch shape: torch.Size([60000, 1, 28, 28])\n","Labels batch shape: torch.Size([60000])\n"]}],"source":["train = torchvision.datasets.FashionMNIST(root = './', train = True, download = True, transform = torchvision.transforms.Compose([\n","        torchvision.transforms.ToTensor(), #torchvision.transforms.Normalize((trainmean,), (trainstd,))                                 \n","    ])\n",")\n","trainshuffled = torch.utils.data.DataLoader(train, batch_size=60000, shuffle=True) \n","train_labels = trainshuffled.dataset.targets\n","train_data = trainshuffled.dataset.data\n","\n","#FOR MLP \n","train_dataloader = DataLoader(train, batch_size=60000, shuffle=True)\n","train_x, train_y = next(iter(train_dataloader))\n","print(f\"Feature batch shape: {train_x.size()}\")\n","print(f\"Labels batch shape: {train_y.size()}\")\n","#NICHOLAS USE THESE FOR TRAINING\n","xtrain = np.array(train_x.squeeze()).reshape(60000, 28*28)\n","ytrain = np.array(train_y)\n","\n","#FOR CNN\n","train_dataloader = DataLoader(train, batch_size=batchsize, shuffle=False)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":974,"status":"ok","timestamp":1649083685787,"user":{"displayName":"Jonayed Islam","userId":"15230808736385328806"},"user_tz":240},"id":"2OeyRchHTO9p","outputId":"f63d0235-6627-4e0a-9c94-0f7e8100372a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Feature batch shape: torch.Size([10000, 1, 28, 28])\n","Labels batch shape: torch.Size([10000])\n"]}],"source":["test = torchvision.datasets.FashionMNIST(root = './', train = False, download = True, transform = torchvision.transforms.Compose([\n","        torchvision.transforms.ToTensor(), #torchvision.transforms.Normalize((testmean,), (teststd,))                                 \n","    ])\n",")\n","testshuffled = torch.utils.data.DataLoader(test, batch_size=60000, shuffle=True) \n","test_labels = testshuffled.dataset.targets\n","test_data = testshuffled.dataset.data\n","\n","#FOR MLP \n","test_dataloader = DataLoader(test, batch_size=60000, shuffle=True)\n","test_x, test_y = next(iter(test_dataloader))\n","print(f\"Feature batch shape: {test_x.size()}\")\n","print(f\"Labels batch shape: {test_y.size()}\")\n","#NICHOLAS USE THESE FOR TRAINING\n","xtest = np.array(test_x.squeeze()).reshape(10000, 28*28)\n","ytest = np.array(test_y)\n","\n","\n","#For CNN\n","test_dataloader = DataLoader(test, batch_size=10000, shuffle=False)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1649083685788,"user":{"displayName":"Jonayed Islam","userId":"15230808736385328806"},"user_tz":240},"id":"wUcO7BpgxQPI","outputId":"d197530d-7cfd-47dd-df38-7745cb627d12"},"outputs":[{"output_type":"stream","name":"stdout","text":["train label distribution [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]\n","test label distribution [1000 1000 1000 1000 1000 1000 1000 1000 1000 1000]\n"]}],"source":["print(\"train label distribution\" , np.bincount(ytrain))\n","print(\"test label distribution\" , np.bincount(ytest))"]},{"cell_type":"code","source":["imgplot = plt.imshow(train_x[68].squeeze(),cmap='gray')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264},"id":"2_N059A5GuiJ","executionInfo":{"status":"ok","timestamp":1649039214118,"user_tz":240,"elapsed":312,"user":{"displayName":"Jonayed Islam","userId":"15230808736385328806"}},"outputId":"80d183c5-456b-421f-89c3-d9342278fe9e"},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"weA24pZbU6UB"},"source":["# MLP"]},{"cell_type":"markdown","metadata":{"id":"1BimDzkyW8Qp"},"source":["## Activations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O_GKd4sQW8CT"},"outputs":[],"source":["def softmax(input):\n","  # input -= np.max(input)\n","  # output = []\n","  # for col in input.T:\n","  #     sum = np.sum(np.exp(col))\n","  #     output_col = []\n","  #     for element in col:\n","  #       output_col.append(np.exp(element) / sum)\n","  #     output.append(output_col)\n","  # return np.array(output).T\n","  input -= np.max(input)\n","  log_output = []\n","  for col in input.T:\n","      log_sum = np.log(np.sum(np.exp(col)))\n","      output_col = []\n","      for element in col:\n","        output_col.append(element - log_sum)\n","      log_output.append(output_col)\n","  return np.exp(np.array(log_output).T)\n","\n","def activation(array, activation=None):\n","  if(activation == \"relu\"):\n","      return np.maximum(np.zeros(array.shape), array)\n","\n","  elif(activation == \"tanh\"):\n","    return np.tanh(array)\n","\n","  elif(activation == \"leaky-relu\"):\n","    leaky_relu_coef = 0.001\n","    return np.maximum(leaky_relu_coef * array, array)\n","\n","  elif(activation == \"sigmoid\"):\n","    return (1 / (1 + np.exp(-array)))\n","\n","  else:\n","    return array  # Pass through activation\n","\n","def derivative_activation(array, activation=None):\n","  if(activation == \"relu\"):\n","      return np.where(array > 0, 1, 0)\n","\n","  elif(activation == \"tanh\"):\n","    return (1 - np.tanh(array)*np.tanh(array))\n","\n","  elif(activation == \"leaky-relu\"):\n","    leaky_relu_coef = 0.001\n","    return np.where(array > 0, 1, leaky_relu_coef)\n","\n","  elif(activation == \"sigmoid\"):\n","    return (1 / (1 + np.exp(-array))) * (1 - (1 / (1 + np.exp(-array))))\n","\n","  else:\n","    return 1"]},{"cell_type":"markdown","metadata":{"id":"LWNiyszWY_Gb"},"source":["##MLP Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZT1oFylJZCXz"},"outputs":[],"source":["class mlp:\n","  def __init__(self, x, y, num_hidden_layers, M):\n","    # self.task = task\n","    self.num_hidden_layeres = num_hidden_layers\n","    self.M = M\n","    self.N = x.shape[0]\n","    self.D = x.shape[1]\n","    self.C = y.shape[1]\n","    if(self.N != y.shape[0]):\n","      raise(\"Dimension mismatch!\")\n","    \n","  def fit(self, x, y, optimizer):\n","    N, D = x.shape\n","    def gradient(x, y, params):\n","      # v = params[0]  # PART 1\n","      # dparams = []\n","\n","      v, w = params  # PART 2\n","      q = np.dot(x, v)\n","      z = activation(q, \"relu\")\n","      u = np.dot(z,w)\n","      yh = softmax(u)\n","      dy = yh - y\n","      dw = np.dot(z.T, dy)/N\n","\n","      # dz = np.dot(dy, w.T)\n","      dz = np.outer(dy, w)\n","      print(\"dz shape: \" + str(dz.shape))\n","      print(\"dz shape: \" + str(dz.shape))\n","\n","      dv = np.dot(x.T, dz * derivative_activation(q, \"relu\"))/N  # PROBLEM HERE\n","\n","      dparams = [dv, dw]\n","\n","      # v, w, t = params  # PART 3\n","      # dparams = []\n","      return dparams\n","\n","    # No hidden layers --> PART 1\n","    # v = np.random.randn(self.task.get_num_outputs, self.task.get_num_inputs) * 0.01\n","    # self.params0 = [v]\n","\n","    # Two hidden layers --> Part 3\n","    # v = np.random.randn(self.task.get_num_inputs, self.M[0]) * 0.01\n","    # w = np.random.rand(self.M[0], self.M[1]) * 0.01\n","    # t = np.random.rand(self.M[1], self.task.get_num_outputs) * 0.01\n","    # self.params0 = [v,w,t]\n","\n","    # One hidden layer --> PART 2\n","    v = np.random.randn(self.D, self.M[0]) * 0.1\n","    w = np.random.randn(self.M[0], self.C) * 0.1\n","    params0 = [v,w]\n","\n","    self.params = optimizer.run(gradient, x, y, params0)\n","    return self\n","\n","  def predict(self, x):\n","      v, w = self.params  # PART 2\n","      q = np.dot(x, v)\n","      z = activation(q, \"relu\")\n","      u = np.dot(z,w)\n","      yh = softmax(u)\n","      return yh"]},{"cell_type":"markdown","metadata":{"id":"jGflusj5U_tP"},"source":["## Gradient Descent"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AAMX_ACvU_QM"},"outputs":[],"source":["class GradientDescent:\n","    def __init__(self, learning_rate=.001, max_iters=1e5, epsilon=1e-8):\n","        self.learning_rate = learning_rate\n","        self.max_iters = max_iters\n","        self.epsilon = epsilon\n","        \n","    def run(self, gradient_fn, x, y, params):\n","        norms = np.array([np.inf])\n","        t = 1\n","        while np.any(norms > self.epsilon) and t < self.max_iters:\n","            grad = gradient_fn(x, y, params)\n","            for p in range(len(params)):\n","                params[p] -= self.learning_rate * grad[p]\n","            t += 1\n","            norms = np.array([np.linalg.norm(g) for g in grad])\n","        return params"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ofj3_FMCzIKY"},"outputs":[],"source":["#MLP INPUTS these are all np array that are vectorize\n","print(xtrain.shape)\n","\n","temp = [[0,0,0,0,0,0,0,0,0,0] for _ in range(ytrain.shape[0])]\n","for row_number, row_value in enumerate(ytrain):\n","  temp[row_number][row_value] = 1\n","ytrain_hot = np.array(temp)\n","\n","print(ytrain_hot.shape)\n","print(xtest.shape)\n","print(ytest.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFCyv3FKT3FM"},"outputs":[],"source":["print(ytrain)\n","print(xtrain)\n","\n","print(len(xtrain[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tHzM3RI9Tfpv"},"outputs":[],"source":["x = xtrain\n","y = ytrain_hot\n","\n","model = mlp(x, y, num_hidden_layers=1, M=[128])\n","optimizer = GradientDescent(learning_rate=.1, max_iters=20000)\n","yh = model.fit(x, y, optimizer).predict(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IAH7zfMAZTbz"},"outputs":[],"source":["print(yh)\n","print(np.min(yh))"]},{"cell_type":"markdown","metadata":{"id":"9ZROkPgPsCKf"},"source":["#CNN"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1649083685788,"user":{"displayName":"Jonayed Islam","userId":"15230808736385328806"},"user_tz":240},"id":"TPciAabfsDu7"},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(1, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 8, 4)\n","        self.fc1 = nn.Linear(128, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","        #self.fc3 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","\n","      x = self.pool(F.relu(self.conv1(x)))\n","\n","      x = self.pool(F.relu(self.conv2(x)))\n","\n","      x = torch.flatten(x, 1) # flatten all dimensions except batch\n","      \n","      x = F.relu(self.fc1(x))\n","\n","      #x = F.relu(self.fc2(x))\n","\n","      x = self.fc2(x)\n","      #x = self.fc3(x)\n","      return x\n","\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":194,"status":"ok","timestamp":1649085388103,"user":{"displayName":"Jonayed Islam","userId":"15230808736385328806"},"user_tz":240},"id":"G8l1E49fyfi6"},"outputs":[],"source":["\n","\n","lr = 0.001\n","momentum = 0.9\n","epochs = 1\n","\n","def trainPredictCNN(lr=0.001, epochs = 100,batchsize = 2000, optimizerChoice = 'Adam'):\n","  \n","  #create data loaders with specified batch size \n","  train_dataloader = DataLoader(train, batch_size=batchsize, shuffle=True)\n","  test_dataloader = DataLoader(test, batch_size=10000, shuffle=False)\n","  \n","  #for using gpu\n","  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","  #print(device)\n","\n","  \n","  net = CNN()\n","  net.to(device)\n","  ce = nn.CrossEntropyLoss()\n","  if optimizerChoice == 'Adam':\n","    optimizer = optim.Adam(net.parameters(), lr=lr)\n","  \n","  elif optimizerChoice == 'sgd':\n","    optimizer = optim.SGD(net.parameters(), lr=lr,momentum=0.9)\n","\n","  elif optimizerChoice == 'ada':\n","    optimizer = optim.Adagrad(net.parameters(), lr=lr)\n","\n","  e = 0\n","  for epoch in range(epochs):\n","    eloss = 0.0\n","    right = 0\n","    #Loop through each batch of training set\n","    for data in train_dataloader:\n","        x, y = data[0].to(device), data[1].to(device)\n","        optimizer.zero_grad()\n","\n","        #forward propagation \n","        pred = net(x)\n","\n","        #Calculate Cross entropy loss\n","        loss = ce(pred, y)\n","\n","        #Run backpropagation\n","        loss.backward()\n","\n","        #Optimize weights\n","        optimizer.step()\n","\n","        #Add loss of current batch to epoch loss\n","        eloss += loss.item()\n","        \n","        \n","        s, predicted = torch.max(pred.data, 1)\n","        right += (predicted == y).sum().item()\n","\n","    trainacc = right / 60000 * 100\n","    #print(\"epoch \" + str(e) + \" loss: \" + str(eloss) + \"accuracy: \" , trainacc)\n","    e +=1\n","  #print('Finished Training')\n","\n","\n","  #print accuracy on test set\n","  right = 0\n","\n","  with torch.no_grad():\n","      for data in test_dataloader:\n","          images, labels = data[0].to(device), data[1].to(device)\n","          outputs = net(images)\n","          #argmax on predictions\n","          s, predicted = torch.max(outputs.data, 1)\n","          right += (predicted == labels).sum().item()\n","        \n","\n","\n","          #For plotting confusion matrix\n","          if 0: \n","            y_true = labels.tolist()\n","            y_pred = predicted.tolist()\n","            confusion = confusion_matrix(y_true, y_pred)\n","            confusionDF = pd.DataFrame(confusion, index = test_dataloader.dataset.classes,\n","                            columns = test_dataloader.dataset.classes)\n","            plt.figure(figsize = (20,14))\n","            sn.heatmap(confusionDF, annot=True)\n","  acc = right / 10000 * 100\n","  print('Test Accuracy: ' , acc)\n","\n","  \n","  return acc\n"]},{"cell_type":"code","source":["#to generate confusion matrix and get accuracy with best hyperparams\n","acc = trainPredictCNN(epochs=250,lr=0.005,batchsize=200)\n","print(acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RthMm6R8Z0jd","executionInfo":{"status":"ok","timestamp":1649088637707,"user_tz":240,"elapsed":3248052,"user":{"displayName":"Jonayed Islam","userId":"15230808736385328806"}},"outputId":"6a569273-b416-4a4d-9da1-ada1e018a009"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 0 loss: 210.11766782402992accuracy:  74.08166666666666\n","epoch 1 loss: 135.7685346007347accuracy:  83.705\n","epoch 2 loss: 118.88887006044388accuracy:  85.61333333333333\n","epoch 3 loss: 109.35671569406986accuracy:  86.68333333333334\n","epoch 4 loss: 102.73652118444443accuracy:  87.41333333333333\n","epoch 5 loss: 99.25679625570774accuracy:  87.93833333333333\n","epoch 6 loss: 94.93816588819027accuracy:  88.255\n","epoch 7 loss: 92.99227423965931accuracy:  88.57166666666667\n","epoch 8 loss: 88.56239852309227accuracy:  89.08666666666667\n","epoch 9 loss: 85.99670740962029accuracy:  89.23666666666666\n","epoch 10 loss: 85.54280127584934accuracy:  89.35499999999999\n","epoch 11 loss: 82.6100530475378accuracy:  89.685\n","epoch 12 loss: 82.60158021748066accuracy:  89.735\n","epoch 13 loss: 80.25380021333694accuracy:  89.91\n","epoch 14 loss: 78.23809014260769accuracy:  90.24166666666666\n","epoch 15 loss: 76.92625053226948accuracy:  90.34\n","epoch 16 loss: 74.87912811338902accuracy:  90.64833333333333\n","epoch 17 loss: 73.60158985853195accuracy:  90.745\n","epoch 18 loss: 72.8309333473444accuracy:  90.81666666666666\n","epoch 19 loss: 71.0623310059309accuracy:  90.98333333333333\n","epoch 20 loss: 71.05152870714664accuracy:  90.94\n","epoch 21 loss: 68.83303306251764accuracy:  91.30166666666668\n","epoch 22 loss: 69.48125983774662accuracy:  91.14166666666667\n","epoch 23 loss: 68.17289131134748accuracy:  91.36833333333333\n","epoch 24 loss: 67.13968893885612accuracy:  91.41166666666666\n","epoch 25 loss: 68.03259733319283accuracy:  91.46\n","epoch 26 loss: 65.22273138165474accuracy:  91.77\n","epoch 27 loss: 65.37202458828688accuracy:  91.72\n","epoch 28 loss: 64.53851579129696accuracy:  91.90166666666667\n","epoch 29 loss: 62.65725427120924accuracy:  91.97166666666666\n","epoch 30 loss: 62.862451419234276accuracy:  91.91833333333334\n","epoch 31 loss: 62.49731856584549accuracy:  92.05\n","epoch 32 loss: 59.52231539040804accuracy:  92.43\n","epoch 33 loss: 61.8450697734952accuracy:  92.105\n","epoch 34 loss: 59.43007116019726accuracy:  92.45\n","epoch 35 loss: 59.09399175643921accuracy:  92.38499999999999\n","epoch 36 loss: 58.65065690129995accuracy:  92.50833333333334\n","epoch 37 loss: 57.600191317498684accuracy:  92.60000000000001\n","epoch 38 loss: 58.16855761408806accuracy:  92.53333333333333\n","epoch 39 loss: 57.32784830778837accuracy:  92.74666666666667\n","epoch 40 loss: 56.85811446234584accuracy:  92.805\n","epoch 41 loss: 56.11350616067648accuracy:  92.73166666666667\n","epoch 42 loss: 56.2567255795002accuracy:  92.78833333333333\n","epoch 43 loss: 56.61241223663092accuracy:  92.805\n","epoch 44 loss: 52.98414937406778accuracy:  93.33\n","epoch 45 loss: 53.94103742390871accuracy:  93.05833333333334\n","epoch 46 loss: 55.29046677052975accuracy:  92.97166666666666\n","epoch 47 loss: 53.5168362557888accuracy:  93.12333333333333\n","epoch 48 loss: 52.23563779145479accuracy:  93.28666666666666\n","epoch 49 loss: 53.719118885695934accuracy:  93.11500000000001\n","epoch 50 loss: 52.70483023673296accuracy:  93.18833333333333\n","epoch 51 loss: 53.610548570752144accuracy:  93.21166666666667\n","epoch 52 loss: 52.496175430715084accuracy:  93.28333333333333\n","epoch 53 loss: 51.926143281161785accuracy:  93.35333333333334\n","epoch 54 loss: 51.2262597233057accuracy:  93.43\n","epoch 55 loss: 51.12161864340305accuracy:  93.425\n","epoch 56 loss: 50.6645779684186accuracy:  93.465\n","epoch 57 loss: 49.854768358170986accuracy:  93.68333333333332\n","epoch 58 loss: 50.737119391560555accuracy:  93.39\n","epoch 59 loss: 49.44187582284212accuracy:  93.62666666666667\n","epoch 60 loss: 49.63668421655893accuracy:  93.55666666666667\n","epoch 61 loss: 49.368385054171085accuracy:  93.72166666666666\n","epoch 62 loss: 49.072989508509636accuracy:  93.71000000000001\n","epoch 63 loss: 51.116698272526264accuracy:  93.47\n","epoch 64 loss: 46.7746572047472accuracy:  93.99\n","epoch 65 loss: 47.319178469479084accuracy:  93.94666666666667\n","epoch 66 loss: 48.51076892763376accuracy:  93.875\n","epoch 67 loss: 45.88570187240839accuracy:  94.09666666666666\n","epoch 68 loss: 48.50150453299284accuracy:  93.77666666666667\n","epoch 69 loss: 46.357602544128895accuracy:  94.04333333333334\n","epoch 70 loss: 47.9207959510386accuracy:  93.88333333333333\n","epoch 71 loss: 46.73479904234409accuracy:  94.03166666666667\n","epoch 72 loss: 45.762412302196026accuracy:  94.02333333333334\n","epoch 73 loss: 47.27706250548363accuracy:  93.88\n","epoch 74 loss: 47.60835049673915accuracy:  93.86333333333333\n","epoch 75 loss: 46.519676093012094accuracy:  93.97833333333332\n","epoch 76 loss: 46.46219553053379accuracy:  94.085\n","epoch 77 loss: 45.31941005960107accuracy:  94.11333333333334\n","epoch 78 loss: 43.67662591487169accuracy:  94.31833333333334\n","epoch 79 loss: 47.09142950922251accuracy:  94.03666666666666\n","epoch 80 loss: 46.183257438242435accuracy:  94.14\n","epoch 81 loss: 44.96837971359491accuracy:  94.245\n","epoch 82 loss: 44.328474923968315accuracy:  94.32000000000001\n","epoch 83 loss: 45.96749583631754accuracy:  94.18833333333333\n","epoch 84 loss: 44.74958277866244accuracy:  94.19999999999999\n","epoch 85 loss: 42.741554137319326accuracy:  94.63666666666667\n","epoch 86 loss: 44.323443815112114accuracy:  94.28166666666667\n","epoch 87 loss: 44.83752863109112accuracy:  94.28166666666667\n","epoch 88 loss: 44.13729330897331accuracy:  94.33666666666667\n","epoch 89 loss: 43.78600673004985accuracy:  94.35166666666667\n","epoch 90 loss: 45.17530796304345accuracy:  94.22\n","epoch 91 loss: 44.693223021924496accuracy:  94.28666666666666\n","epoch 92 loss: 42.164724446833134accuracy:  94.585\n","epoch 93 loss: 42.216603215783834accuracy:  94.53166666666667\n","epoch 94 loss: 40.55373748019338accuracy:  94.845\n","epoch 95 loss: 42.3959425278008accuracy:  94.61500000000001\n","epoch 96 loss: 42.588054187595844accuracy:  94.58\n","epoch 97 loss: 42.9781279861927accuracy:  94.49166666666666\n","epoch 98 loss: 43.859298907220364accuracy:  94.35666666666667\n","epoch 99 loss: 42.129006788134575accuracy:  94.55666666666667\n","epoch 100 loss: 46.11819626390934accuracy:  94.17833333333333\n","epoch 101 loss: 44.01468697562814accuracy:  94.39833333333333\n","epoch 102 loss: 42.620149940252304accuracy:  94.58833333333332\n","epoch 103 loss: 41.04346166178584accuracy:  94.80499999999999\n","epoch 104 loss: 40.375545643270016accuracy:  94.80166666666666\n","epoch 105 loss: 43.95227996632457accuracy:  94.305\n","epoch 106 loss: 41.05338231101632accuracy:  94.71666666666667\n","epoch 107 loss: 41.47381057217717accuracy:  94.69333333333333\n","epoch 108 loss: 41.21006425842643accuracy:  94.695\n","epoch 109 loss: 38.56198677420616accuracy:  95.06833333333333\n","epoch 110 loss: 41.93175618723035accuracy:  94.64833333333334\n","epoch 111 loss: 43.10933542996645accuracy:  94.52333333333334\n","epoch 112 loss: 40.36198174953461accuracy:  94.905\n","epoch 113 loss: 42.64766689389944accuracy:  94.56166666666667\n","epoch 114 loss: 39.687382094562054accuracy:  94.965\n","epoch 115 loss: 40.87338179722428accuracy:  94.74000000000001\n","epoch 116 loss: 42.525803819298744accuracy:  94.55333333333333\n","epoch 117 loss: 40.68977785855532accuracy:  94.75166666666667\n","epoch 118 loss: 40.96577399596572accuracy:  94.85166666666667\n","epoch 119 loss: 40.06718610227108accuracy:  94.91000000000001\n","epoch 120 loss: 40.52581722289324accuracy:  94.94500000000001\n","epoch 121 loss: 40.33511268720031accuracy:  94.91000000000001\n","epoch 122 loss: 40.25805400684476accuracy:  94.845\n","epoch 123 loss: 39.56512178108096accuracy:  94.89\n","epoch 124 loss: 38.6286733597517accuracy:  95.035\n","epoch 125 loss: 38.084218975156546accuracy:  95.155\n","epoch 126 loss: 43.96778102219105accuracy:  94.57333333333334\n","epoch 127 loss: 39.313576102256775accuracy:  95.085\n","epoch 128 loss: 39.45449636131525accuracy:  94.97166666666666\n","epoch 129 loss: 38.40262158960104accuracy:  95.0\n","epoch 130 loss: 40.08917561545968accuracy:  95.015\n","epoch 131 loss: 42.592704117298126accuracy:  94.715\n","epoch 132 loss: 37.13093751296401accuracy:  95.26\n","epoch 133 loss: 37.74117944017053accuracy:  95.15333333333334\n","epoch 134 loss: 40.02104368805885accuracy:  94.80666666666666\n","epoch 135 loss: 40.122463162988424accuracy:  94.91166666666668\n","epoch 136 loss: 37.30925538390875accuracy:  95.25666666666666\n","epoch 137 loss: 38.920212883502245accuracy:  95.025\n","epoch 138 loss: 39.477223321795464accuracy:  95.015\n","epoch 139 loss: 38.2432887814939accuracy:  95.19\n","epoch 140 loss: 35.900011505931616accuracy:  95.39\n","epoch 141 loss: 38.58676827326417accuracy:  95.095\n","epoch 142 loss: 37.25463495403528accuracy:  95.275\n","epoch 143 loss: 39.63546751067042accuracy:  95.07333333333334\n","epoch 144 loss: 42.08167342841625accuracy:  94.81\n","epoch 145 loss: 35.71843456104398accuracy:  95.39999999999999\n","epoch 146 loss: 36.27560730278492accuracy:  95.37666666666667\n","epoch 147 loss: 36.774328488856554accuracy:  95.28999999999999\n","epoch 148 loss: 36.707037437707186accuracy:  95.37833333333333\n","epoch 149 loss: 41.00220240652561accuracy:  94.85166666666667\n","epoch 150 loss: 39.11960810422897accuracy:  95.02833333333334\n","epoch 151 loss: 34.834344156086445accuracy:  95.55833333333334\n","epoch 152 loss: 38.949813440442085accuracy:  95.14833333333334\n","epoch 153 loss: 38.20297443121672accuracy:  95.22\n","epoch 154 loss: 36.655504405498505accuracy:  95.40833333333333\n","epoch 155 loss: 38.08838241174817accuracy:  95.195\n","epoch 156 loss: 36.087586890906096accuracy:  95.44666666666667\n","epoch 157 loss: 38.41237445920706accuracy:  95.145\n","epoch 158 loss: 41.61907956749201accuracy:  94.73166666666667\n","epoch 159 loss: 38.53631353750825accuracy:  95.07166666666666\n","epoch 160 loss: 38.224448040127754accuracy:  95.165\n","epoch 161 loss: 36.00533780269325accuracy:  95.44166666666666\n","epoch 162 loss: 38.16683793067932accuracy:  95.19333333333333\n","epoch 163 loss: 38.887940511107445accuracy:  95.11833333333334\n","epoch 164 loss: 33.79194451496005accuracy:  95.71666666666667\n","epoch 165 loss: 39.87990229204297accuracy:  95.01333333333334\n","epoch 166 loss: 37.904881812632084accuracy:  95.28166666666667\n","epoch 167 loss: 35.26902860030532accuracy:  95.45333333333333\n","epoch 168 loss: 34.72603505849838accuracy:  95.52833333333334\n","epoch 169 loss: 36.663787227123976accuracy:  95.39\n","epoch 170 loss: 36.53133340924978accuracy:  95.40833333333333\n","epoch 171 loss: 37.74025810137391accuracy:  95.26666666666667\n","epoch 172 loss: 37.612786538898945accuracy:  95.33833333333334\n","epoch 173 loss: 40.958284232765436accuracy:  94.895\n","epoch 174 loss: 36.30515879392624accuracy:  95.455\n","epoch 175 loss: 36.54913818091154accuracy:  95.415\n","epoch 176 loss: 34.35586627200246accuracy:  95.61833333333334\n","epoch 177 loss: 37.56674367189407accuracy:  95.24166666666667\n","epoch 178 loss: 38.954179253429174accuracy:  95.215\n","epoch 179 loss: 35.08941937610507accuracy:  95.54166666666667\n","epoch 180 loss: 33.71190831437707accuracy:  95.7\n","epoch 181 loss: 34.85971289128065accuracy:  95.57\n","epoch 182 loss: 36.86267772689462accuracy:  95.295\n","epoch 183 loss: 34.36180857568979accuracy:  95.58333333333333\n","epoch 184 loss: 37.249079037457705accuracy:  95.35\n","epoch 185 loss: 37.318028163164854accuracy:  95.33333333333334\n","epoch 186 loss: 35.58411683142185accuracy:  95.49499999999999\n","epoch 187 loss: 33.28849809244275accuracy:  95.72166666666668\n","epoch 188 loss: 36.75802109390497accuracy:  95.42833333333334\n","epoch 189 loss: 34.22275624424219accuracy:  95.71833333333333\n","epoch 190 loss: 41.38972606509924accuracy:  95.0\n","epoch 191 loss: 36.11460467427969accuracy:  95.46333333333334\n","epoch 192 loss: 31.253058325499296accuracy:  96.00166666666667\n","epoch 193 loss: 33.56553126871586accuracy:  95.785\n","epoch 194 loss: 38.340106692165136accuracy:  95.32833333333333\n","epoch 195 loss: 34.699817173182964accuracy:  95.625\n","epoch 196 loss: 35.31349781155586accuracy:  95.515\n","epoch 197 loss: 40.77561525627971accuracy:  94.97833333333332\n","epoch 198 loss: 34.02532073482871accuracy:  95.65666666666667\n","epoch 199 loss: 33.74688248895109accuracy:  95.67999999999999\n","epoch 200 loss: 33.910035725682974accuracy:  95.685\n","epoch 201 loss: 35.176445953547955accuracy:  95.53\n","epoch 202 loss: 38.77483817562461accuracy:  95.15\n","epoch 203 loss: 39.174870397895575accuracy:  95.11500000000001\n","epoch 204 loss: 37.05949481204152accuracy:  95.51333333333332\n","epoch 205 loss: 36.58482835441828accuracy:  95.36\n","epoch 206 loss: 32.68402714654803accuracy:  95.8\n","epoch 207 loss: 33.02896826714277accuracy:  95.81\n","epoch 208 loss: 32.281456630676985accuracy:  95.895\n","epoch 209 loss: 37.434863321483135accuracy:  95.32666666666667\n","epoch 210 loss: 36.010310646146536accuracy:  95.53333333333333\n","epoch 211 loss: 36.90296259149909accuracy:  95.34333333333333\n","epoch 212 loss: 34.17346937581897accuracy:  95.71\n","epoch 213 loss: 37.71091282740235accuracy:  95.32333333333334\n","epoch 214 loss: 35.828125793486834accuracy:  95.52000000000001\n","epoch 215 loss: 36.91000294312835accuracy:  95.32333333333334\n","epoch 216 loss: 33.58486273139715accuracy:  95.77\n","epoch 217 loss: 34.13471560925245accuracy:  95.73333333333333\n","epoch 218 loss: 32.91880702599883accuracy:  95.75333333333333\n","epoch 219 loss: 33.85121512040496accuracy:  95.84666666666666\n","epoch 220 loss: 33.004021782428026accuracy:  95.91166666666666\n","epoch 221 loss: 37.71818219870329accuracy:  95.36333333333333\n","epoch 222 loss: 34.43067221343517accuracy:  95.735\n","epoch 223 loss: 32.65746531262994accuracy:  95.92166666666667\n","epoch 224 loss: 39.89783617854118accuracy:  95.20166666666667\n","epoch 225 loss: 34.45539258047938accuracy:  95.57833333333333\n","epoch 226 loss: 33.62601814419031accuracy:  95.74000000000001\n","epoch 227 loss: 35.584753289818764accuracy:  95.545\n","epoch 228 loss: 33.79486329481006accuracy:  95.80333333333333\n","epoch 229 loss: 31.90995032340288accuracy:  95.94\n","epoch 230 loss: 35.85767826065421accuracy:  95.58666666666666\n","epoch 231 loss: 33.35923333093524accuracy:  95.79166666666666\n","epoch 232 loss: 36.50540501251817accuracy:  95.485\n","epoch 233 loss: 36.90533724240959accuracy:  95.46833333333333\n","epoch 234 loss: 32.36124517209828accuracy:  95.97833333333334\n","epoch 235 loss: 34.33572344109416accuracy:  95.775\n","epoch 236 loss: 34.118987273424864accuracy:  95.765\n","epoch 237 loss: 33.08082341775298accuracy:  95.73833333333333\n","epoch 238 loss: 37.95912501215935accuracy:  95.39\n","epoch 239 loss: 36.41116115823388accuracy:  95.45166666666667\n","epoch 240 loss: 34.977881234139204accuracy:  95.60166666666666\n","epoch 241 loss: 34.52449011988938accuracy:  95.75\n","epoch 242 loss: 36.31668711081147accuracy:  95.54\n","epoch 243 loss: 33.112690437585115accuracy:  95.81833333333334\n","epoch 244 loss: 28.96726556867361accuracy:  96.33333333333334\n","epoch 245 loss: 32.48265085928142accuracy:  95.86\n","epoch 246 loss: 36.97770720720291accuracy:  95.50666666666666\n","epoch 247 loss: 39.05520995333791accuracy:  95.23\n","epoch 248 loss: 37.02108348160982accuracy:  95.41666666666667\n","epoch 249 loss: 32.57753727585077accuracy:  95.88166666666666\n","Test Accuracy:  86.37\n","86.37\n"]}]},{"cell_type":"markdown","metadata":{"id":"69TQe0KSkX4N"},"source":["###Crossvalidation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4TLkHXr1kWRO"},"outputs":[],"source":["learning_rates = [0.001,0.005,0.01]\n","epochchoices = [50,100,250,500]\n","#epochchoices = [1]\n","batchchoice = [200,2000,5000,60000]\n","optimizerchoice = ['Adam','ada','sgd']\n","\n","results = []\n","for l in learning_rates:\n","  for e in epochchoices:\n","    for b in batchchoice:\n","      for o in optimizerchoice:\n","        testacc = trainPredictCNN(lr = l, epochs = e, batchsize = b, optimizerChoice = o)\n","        res = [testacc,l,e,b,o]\n","        results.append(res)\n","        print('Test accuracy: ', testacc, \" with lr = \", l , \" epochs = \", e, \" optimizer = \", o, \"batchsize = \", b)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uYMGvHSpndyH"},"outputs":[],"source":["df = pd.DataFrame(results, columns =['Accuracy', 'LR', 'Epochs','Optimizer','Batchsize']) \n","df.to_csv('cnncv.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rUSVussQzjfl"},"outputs":[],"source":["results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1974064,"status":"ok","timestamp":1648959172031,"user":{"displayName":"Jonayed Islam","userId":"15230808736385328806"},"user_tz":240},"id":"YRI7MI_he5HI","outputId":"35c98402-6503-4602-ffa7-4b3a5e817d88"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy:  86.63  with lr =  0.001  epochs =  50  optimizer =  Adam batchsize =  2000\n","Test accuracy:  72.67  with lr =  0.001  epochs =  50  optimizer =  ada batchsize =  2000\n","Test accuracy:  72.61  with lr =  0.001  epochs =  50  optimizer =  sgd batchsize =  2000\n"]}],"source":["learning_rates = [0.001,0.005,0.01]\n","epochchoices = [50,100,250,500]\n","#epochchoices = [1]\n","batchchoice = [200,2000,5000,60000]\n","optimizerchoice = ['Adam','ada','sgd']\n","\n","results = []\n","for o in optimizerchoice:\n","        testacc = trainPredictCNN(lr = 0.001, epochs = 50, batchsize = 2000, optimizerChoice = o)\n","        #res = [testacc,l,e,b,o]\n","        #results.append(res)\n","        print('Test accuracy: ', testacc, \" with lr = \", 0.001 , \" epochs = \", 50, \" optimizer = \", o, \"batchsize = \", 2000)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_RYnJzLtfK9P","outputId":"1bdf1ee1-dcf4-41ac-b711-ed73c18c2d2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy:  88.28  with lr =  0.001  epochs =  50  optimizer = Adam batchsize =  200\n","Test accuracy:  85.32  with lr =  0.001  epochs =  50  optimizer = Adam batchsize =  2000\n","Test accuracy:  84.24000000000001  with lr =  0.001  epochs =  50  optimizer = Adam batchsize =  5000\n"]}],"source":["learning_rates = [0.001,0.005,0.01]\n","epochchoices = [50,100,250,500]\n","#epochchoices = [1]\n","batchchoice = [200,2000,5000,60000]\n","optimizerchoice = ['Adam','ada','sgd']\n","\n","results = []\n","for b in batchchoice:\n","        testacc = trainPredictCNN(lr = 0.001, epochs = 50, batchsize = b, optimizerChoice = 'Adam')\n","        #res = [testacc,l,e,b,o]\n","        #results.append(res)\n","        print('Test accuracy: ', testacc, \" with lr = \", 0.001 , \" epochs = \", 50, \" optimizer = Adam\", \"batchsize = \", b)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"43Nqp0wtfT6d","outputId":"1aaec6eb-d24a-4046-d219-3d65e6640270"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy:  86.55000000000001  with lr =  0.001  epochs =  50  optimizer = Adam batchsize = 2000\n","Test accuracy:  88.56  with lr =  0.005  epochs =  50  optimizer = Adam batchsize = 2000\n","Test accuracy:  88.26  with lr =  0.01  epochs =  50  optimizer = Adam batchsize = 2000\n"]}],"source":["learning_rates = [0.001,0.005,0.01]\n","epochchoices = [50,100,250,500]\n","#epochchoices = [1]\n","batchchoice = [200,2000,5000,60000]\n","optimizerchoice = ['Adam','ada','sgd']\n","\n","results = []\n","for l in learning_rates:\n","        testacc = trainPredictCNN(lr = l, epochs = 50, batchsize = 2000, optimizerChoice = 'Adam')\n","        #res = [testacc,l,e,b,o]\n","        #results.append(res)\n","        print('Test accuracy: ', testacc, \" with lr = \", l , \" epochs = \", 50, \" optimizer = Adam\", \"batchsize = 2000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"S8QnAigegKZZ","outputId":"eceaea60-a93f-446f-c325-277bf42a51f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy:  86.03  with lr = 0.01  epochs =  50  optimizer = Adam batchsize = 2000\n","Test accuracy:  87.17  with lr = 0.01  epochs =  100  optimizer = Adam batchsize = 2000\n","Test accuracy:  88.07000000000001  with lr = 0.01  epochs =  250  optimizer = Adam batchsize = 2000\n","Test accuracy:  88.8  with lr = 0.01  epochs =  500  optimizer = Adam batchsize = 2000\n"]}],"source":["learning_rates = [0.001,0.005,0.01]\n","epochchoices = [50,100,250,500]\n","#epochchoices = [1]\n","batchchoice = [200,2000,5000,60000]\n","optimizerchoice = ['Adam','ada','sgd']\n","\n","results = []\n","for e in epochchoices:\n","        testacc = trainPredictCNN(lr = 0.001, epochs = e, batchsize = 2000, optimizerChoice = 'Adam')\n","        #res = [testacc,l,e,b,o]\n","        #results.append(res)\n","        print('Test accuracy: ', testacc, \" with lr = 0.01\" , \" epochs = \", e, \" optimizer = Adam\", \"batchsize = 2000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gjTZyGHyFj7n"},"outputs":[],"source":["testacc = trainPredictCNN(lr = 0.005, epochs = 250, batchsize = 200, optimizerChoice = 'Adam')\n","print('Test accuracy: ', testacc, \" with lr = 0.005\" , \" epochs = \", 200, \" optimizer = Adam\", \"batchsize = 200\")"]}],"metadata":{"colab":{"collapsed_sections":["0mgRrjQ-UiMc","TyrinVrtUqus"],"name":"A3 Code.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c2ba37d500c8426897d309e934bfb8fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_549d3570fdcf48b9bc1d5f5b89ecb281","IPY_MODEL_c2b50f1160e94e7ba2d6c0da4351146f","IPY_MODEL_f1dc550b0fbe44d6b6c5f88910955ba3"],"layout":"IPY_MODEL_c1b5df538c114c2d90a6d6b8061edffd"}},"549d3570fdcf48b9bc1d5f5b89ecb281":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27755f22e07b4533a6cd1f036bab6e88","placeholder":"â€‹","style":"IPY_MODEL_7a9b7db00ab144289ab05edfdedc2b5b","value":""}},"c2b50f1160e94e7ba2d6c0da4351146f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c3959b55adc4e44b93181c298177443","max":26421880,"min":0,"orientation":"horizontal","style":"IPY_MODEL_303b8e0a6c2f476f86de14e690cae0c3","value":26421880}},"f1dc550b0fbe44d6b6c5f88910955ba3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed392b6d74e34bc591090fa87a1d5fed","placeholder":"â€‹","style":"IPY_MODEL_36dd408c2d8140f28bc49fb15ca0a8fe","value":" 26422272/? [00:02&lt;00:00, 17280233.72it/s]"}},"c1b5df538c114c2d90a6d6b8061edffd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27755f22e07b4533a6cd1f036bab6e88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a9b7db00ab144289ab05edfdedc2b5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c3959b55adc4e44b93181c298177443":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"303b8e0a6c2f476f86de14e690cae0c3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ed392b6d74e34bc591090fa87a1d5fed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36dd408c2d8140f28bc49fb15ca0a8fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7321e15bab347559fdd8b810d351e39":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0b4fbea478c48da8f249af6579544d3","IPY_MODEL_acbc23a8881a4e8b89fc6c3e1f4b2936","IPY_MODEL_5b9186cf350a44b782bc2eb3592d7c06"],"layout":"IPY_MODEL_6c0b3ebd07ba492f903e2fab86ae59cd"}},"e0b4fbea478c48da8f249af6579544d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cbaf45f137f4c2f9370319df73c15d9","placeholder":"â€‹","style":"IPY_MODEL_80d6b8eae5d0446782041136711d312a","value":""}},"acbc23a8881a4e8b89fc6c3e1f4b2936":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_809858bc1b414b5281d5ce29f1d740ad","max":29515,"min":0,"orientation":"horizontal","style":"IPY_MODEL_913959e0d8944bf6b1dff64ba5c057cd","value":29515}},"5b9186cf350a44b782bc2eb3592d7c06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de971789d0e44fbdbfc5ab270b2791d7","placeholder":"â€‹","style":"IPY_MODEL_2483910c1a084ff9a8492aee34d10d31","value":" 29696/? [00:00&lt;00:00, 92022.68it/s]"}},"6c0b3ebd07ba492f903e2fab86ae59cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cbaf45f137f4c2f9370319df73c15d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80d6b8eae5d0446782041136711d312a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"809858bc1b414b5281d5ce29f1d740ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"913959e0d8944bf6b1dff64ba5c057cd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"de971789d0e44fbdbfc5ab270b2791d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2483910c1a084ff9a8492aee34d10d31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af41a2dd0dfd464586207bfc12b7e75e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec7f5cc71bd6432c83a2a25688da675a","IPY_MODEL_042df4ffcf544738a0ddc4a667d7d765","IPY_MODEL_4f9c8fb7519741db916a91748f77c35d"],"layout":"IPY_MODEL_d00d10d3f50a42c39828a54932a28ff7"}},"ec7f5cc71bd6432c83a2a25688da675a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8f1248cc43e4f85ba2d56c33e88e383","placeholder":"â€‹","style":"IPY_MODEL_0e05874a2dec4ecd975841dcf88c8300","value":""}},"042df4ffcf544738a0ddc4a667d7d765":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_778c273fdf6840409db9b951aecc40b9","max":4422102,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd254902e50f48929754ab965d21c9e8","value":4422102}},"4f9c8fb7519741db916a91748f77c35d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d59c0e07fc34711ba281744e99d9902","placeholder":"â€‹","style":"IPY_MODEL_5846f1f851ae4d0fa119904d23ecf84f","value":" 4422656/? [00:01&lt;00:00, 5531108.52it/s]"}},"d00d10d3f50a42c39828a54932a28ff7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8f1248cc43e4f85ba2d56c33e88e383":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e05874a2dec4ecd975841dcf88c8300":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"778c273fdf6840409db9b951aecc40b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd254902e50f48929754ab965d21c9e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3d59c0e07fc34711ba281744e99d9902":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5846f1f851ae4d0fa119904d23ecf84f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8570181d28904a4090ba83f6f9600cfa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_44a36774046e41259bbfd9abbb9e18af","IPY_MODEL_c30deffe234f4a71be74985a86271161","IPY_MODEL_62da865db2d040b0a0253e2c954c33a5"],"layout":"IPY_MODEL_abc2177e726a4907b71fd116f1bc5852"}},"44a36774046e41259bbfd9abbb9e18af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd4c63eb6f754a98b0e5306c38ecd050","placeholder":"â€‹","style":"IPY_MODEL_d4fa0b67a5bb4c8e9cb76af5f39b376a","value":""}},"c30deffe234f4a71be74985a86271161":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_88426f710ecd4bac93d73cd59fa6e5f5","max":5148,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b81c72c3b1354bd49d901b738aa24401","value":5148}},"62da865db2d040b0a0253e2c954c33a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5811583bcfb4315b3b561346adec711","placeholder":"â€‹","style":"IPY_MODEL_38c9c0291c484a968785a7f4ef961630","value":" 6144/? [00:00&lt;00:00, 170484.82it/s]"}},"abc2177e726a4907b71fd116f1bc5852":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd4c63eb6f754a98b0e5306c38ecd050":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4fa0b67a5bb4c8e9cb76af5f39b376a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88426f710ecd4bac93d73cd59fa6e5f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b81c72c3b1354bd49d901b738aa24401":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c5811583bcfb4315b3b561346adec711":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38c9c0291c484a968785a7f4ef961630":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}